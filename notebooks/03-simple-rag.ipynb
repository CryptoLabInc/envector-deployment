{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4626e955",
   "metadata": {},
   "source": [
    "# Simple Encrypted RAG with enVector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aae95e9",
   "metadata": {},
   "source": [
    "In this tutorial, we will walk through the steps to use the enVector SDK for Encrypted Retrieval-Augmented Generation (Encrypted RAG) using fully homomorphic encryption (FHE)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e16ee0a",
   "metadata": {},
   "source": [
    "## Import SDK\n",
    "\n",
    "First, you should install and import the `es2` package to use enVector Python APIs.\n",
    "Before installing, make sure you have Python 3.12 and a virtual environment on your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d41fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import es2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae05f72",
   "metadata": {},
   "source": [
    "## Initialize\n",
    "\n",
    "To use the enVector service, initialization is required. \n",
    "\n",
    "The following initialization step includes establishing a connection to the enVector server and configuring cryptographic settings necessary for vector search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec72dfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "es2.init(\n",
    "    address=\"localhost:50050\",\n",
    "    # access_token=\"...\", # if needed\n",
    "    key_path=\"./keys\",\n",
    "    key_id=\"rag_key_id\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb306a5",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "\n",
    "### Prepare Plaintext Vectors\n",
    "\n",
    "To perform RAG, we need to prepare the plaintext text embedding vectors.\n",
    "\n",
    "Note that these vectors should be normalized for the identification metric, cosine similarity. This is just one example of text embedding that uses sentence-transformers, you can also use your own embedding model to generate vectors from your text dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f600cd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Union\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load a pretrained Sentence Transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# 2. Calculate embeddings by calling model.encode()\n",
    "def get_embedding(texts: Union[str, List[str]], dim=None) -> np.ndarray:\n",
    "    BATCH_SIZE=128\n",
    "    if dim is None:\n",
    "        dim = model.get_sentence_embedding_dimension()\n",
    "    if isinstance(texts, list):\n",
    "        embeddings = np.empty((0, dim))\n",
    "        for i in range(0, len(texts), BATCH_SIZE):\n",
    "            batch_texts = texts[i : i + BATCH_SIZE]\n",
    "            batch_embeddings = model.encode(batch_texts)\n",
    "            embeddings = np.vstack([embeddings, batch_embeddings])\n",
    "        return embeddings\n",
    "    else:\n",
    "        return model.encode(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee97f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare vectors to be indexed\n",
    "texts = [\n",
    "    \"The capital of France is Paris.\",\n",
    "    \"The capital of Germany is Berlin.\",\n",
    "    \"The capital of Italy is Rome.\",\n",
    "    \"The capital of Canada is Ottawa.\",\n",
    "    \"The capital of South Korea is Seoul.\",\n",
    "]\n",
    "\n",
    "# Get embeddings\n",
    "vectors = get_embedding(texts)\n",
    "dim = vectors.shape[1]\n",
    "\n",
    "print(f\"Vector Dimension: {dim}\")\n",
    "print(f\"Number of Vectors: {vectors.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f660d6",
   "metadata": {},
   "source": [
    "## Create Index and Insert Data\n",
    "\n",
    "For encrypted similarity search, we first prepare a vector index, called `Index`, to store encrypted vectors and their metadata in the enVector system.\n",
    "An index is defined by its name and the dimensionality of the vectors it will store.\n",
    "The dimensionality must match the size of the vectors you plan to insert.\n",
    "This step ensures the index is properly configured to handle your data.\n",
    "\n",
    "Once the index is ready, you can insert data into it.\n",
    "This first encrypts the vectors using the generated encryption keys and inserts them into the created index.\n",
    "The data to be inserted can be in the form of vectors and associated metadata. \n",
    "The metadata can provide additional context or information about the vectors, such as their source or relevance.\n",
    "Each vector should match the dimensionality specified during index creation.\n",
    "\n",
    "Additionally, metadata can be attached to each vector to provide context or additional information. \n",
    "This step is essential for RAG.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924e9f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = es2.create_index(\"rag_index\", dim=dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d77744",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.insert(vectors, metadata=texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60761faf",
   "metadata": {},
   "source": [
    "## Encrypted Similarity Search\n",
    "\n",
    "### Prepare query\n",
    "\n",
    "First, prepare a query for encrypted search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6e4857",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = \"What is the capital of France?\"\n",
    "\n",
    "query_vector = get_embedding(query_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b07e64e",
   "metadata": {},
   "source": [
    "### Encrypted search on the index\n",
    "\n",
    "Let's perform an encrypted similarity search for encrypted RAG. \n",
    "\n",
    "Once the encrypted vector index and encrypted query vectors are ready, we can perform a similarity search on encrypted data without decrypting it.\n",
    "The `index` object contains the decryption key, enabling the enVector server to return encrypted scores. \n",
    "These scores are decrypted by the client to retrieve the top-k relevant results along with their indices.\n",
    "After identifying the indices by decryption and top-k selection, we retrieve the encrypted documents and decrypt them to obtain the plaintext.\n",
    "\n",
    "This process ensures secure and efficient similarity search operations, even when working with encrypted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c59a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = index.search(query_vector, top_k=1, output_fields=[\"metadata\"])[0]\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4b8d0a",
   "metadata": {},
   "source": [
    "### Generate Answers with Retrieval-augmented Context\n",
    "\n",
    "Once the decrypted documents are retrieved, we can use an LLM (e.g. OpenAI's GPT) to generate answers based on the retrieved documents.\n",
    "\n",
    "In this example, we use the gpt-oss model running locally with ollama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0f2f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = [res[\"metadata\"] for res in result]\n",
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dccb5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def generate_answer(docs, query, model=\"gpt-oss\"):\n",
    "    instruction = \"You are an assistant that answers questions based on the provided documents.\"\n",
    "    prompt = f\"\"\"{instruction}:\\n\\n[Documents]\\n\"\"\"\n",
    "    for doc in docs:\n",
    "        prompt += f\"- {doc}\\n\"\n",
    "    prompt += f\"\\n[Question]\\n{query}\\n[Answer]\\n\"\n",
    "\n",
    "    response = requests.post(\n",
    "        \"http://localhost:11434/api/chat\",\n",
    "        json={\n",
    "            \"model\": model,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": instruction},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            \"stream\": False\n",
    "        }\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    return response.json()[\"message\"][\"content\"].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11536d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "answer = generate_answer(retrieved_docs, query_text)\n",
    "print(f\"Generated Answer: \\n{answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9455f87",
   "metadata": {},
   "source": [
    "### Clean Up\n",
    "\n",
    "We can delete the created index and the registered key when they are no longer needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684a8a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "es2.drop_index(\"rag_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8807c5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "es2.delete_key(\"rag_key_id\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "es2-sdk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
